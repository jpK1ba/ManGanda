{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b34282",
   "metadata": {},
   "source": [
    "***\n",
    "<img src='./saves/manganda.png'></img>\n",
    "<div class=\"center\" style=\"padding: 1px; height: 70px; background: black; text-align: center;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Regressive Approach in Rating Mangas thru Sample Art</h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "by : JP Fabrero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f70d2",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"center\" style=\"padding: 1px; height: 60px; background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               margin: 15px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Introduction\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "Are you tired of being inloved in that new manga you're reading, only to know that the series will soon be dropped or discontinued? As a fellow manga enthusiast, I understand the heartbreak and disappointment of investing time and energy into a manga that ultimately falls short. Especially when it can be exhausting to choose your next adventure with countless series puoring in the industry, waiting to be explored. But, what if you could navigate this sea of manga with ease, armed with insights into which series are likely to earn support and last longer?\n",
    "\n",
    "I've pondered how I might better evaluate mangas without pouring hours of research and reading reviews and decided to tackle this problem by use of Deep Learning. In this blog, I'm taking out all the literary elements of a manga and looking closer at the key visual elements that make a manga shine. Using only samples of manga's panels or pages, I'm building a model that learns all the relevant art style, character design, etc. By analyzing these factors, my model, ManGanda, aims and attempts to provide a sneak peek of a manga's potential rating.\n",
    "\n",
    "By undertaking this project, I seek to help both publishers and readers make better-informed decisions about which manga series to invest in and promote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918f0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"center\" style=\"padding: 1px; height: 60px; background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               margin: 15px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Importing Libraries and Utility Functions\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "For this project, I made a lot scripts with utility functions for the various necessary steps. I've imported them here, along with some other libraries.\n",
    "\n",
    "See <a href='https://github.com/jpK1ba/ManGanda/blob/master/utils/utility.py'>code here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd9b145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:30.736794Z",
     "start_time": "2023-06-29T13:18:27.327754Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Necessary customizations for my machine (optional)\n",
    "import os\n",
    "os.environ['SKIMAGE_DATADIR'] = '/tmp/.skimage_cache'\n",
    "os.environ['XDG_CACHE_HOME'] = '/home/msds2023/jfabrero/.cache'\n",
    "\n",
    "# Importing the necessary libraries and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.pyjanitor import auto_toc\n",
    "from utils.pickling import load_pkl, save_pkl\n",
    "from utils.data_collection import get_data, download_mangas, get_annotations\n",
    "from utils.dataset import MangaDataset\n",
    "from utils.dataloader import MangaDataloader\n",
    "from utils.manganda import MangaModel, train_model\n",
    "from utils.mangagradcam import MangaGradCAM\n",
    "from utils.utility import (plot_ratings,\n",
    "                           get_baseline,\n",
    "                           eval_model,\n",
    "                           plot_predictions,\n",
    "                           plot_test,\n",
    "                           plot_saliencies)\n",
    "\n",
    "toc = auto_toc(row_align='left')\n",
    "\n",
    "# For cleanliness\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c93738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"center\" style=\"padding: 1px; height: 60px; background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               margin: 15px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Data Collection\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "At the roots of all great results are robust models and relevant data. With that in mind, to initiate this endeavor, I first gathered a list of top rated mangas from MangaList, https://myanimelist.net/topmanga.php?type=manga, alongside with the target, the manga rating. I made the `get_data` function to take care of that.\n",
    "\n",
    "Next was collecting the manga samples, I made a web crawler to scour a manga scan site I know of, try to look for each manga in the list, and download the panels if available. For fidelity, the sampling were done by getting a set of random chapters and taking the a defined number of panels in the middle of each chapter (this is to avoid getting cover pages). The function `download_mangas` does just that.\n",
    "\n",
    "Finally, to conclude the data collection, I made a function to prepare the annotations for all the successfully sampled mangas in preparation for model training. Unfortunately, during my initial training attempts, I found a lot of errors and discrepancies such as having duplicates and corrupted images. With that, I added some checking functionalities in the `get_annotations` to handle those and ensure that the images to be utilized are fit for training.\n",
    "\n",
    "See <a href='https://github.com/jpK1ba/ManGanda/blob/master/utils/data_collection.py'>code here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247bf381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:30.776490Z",
     "start_time": "2023-06-29T13:18:30.739750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are already downloaded!\n",
      "Download Rate: 25.65%\n"
     ]
    }
   ],
   "source": [
    "df_top = get_data(5_000) # Top 5_000\n",
    "df_dl = download_mangas(df_top) # Dataframe of sampled manga details\n",
    "get_annotations(df_dl) # Write annotations based from sampled mangas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f65b4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:31.719576Z",
     "start_time": "2023-06-29T13:18:30.778745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure1.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig1\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 1.</b> Sample Panel - Haikyuu!! by Furudate Haruichi.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(plt.imread('saves/tsukki.png')) # Displaying a sample panel\n",
    "plt.axis('off')\n",
    "toc.add_fig('Sample Panel - Haikyuu!! by Furudate Haruichi', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b06c3b",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Dataset and Dataloader\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "Next, I utilized the Torch library to create custom datasets and build the dataloader.\n",
    "\n",
    "In the dataset, `MangaDataset`, every data point or image is preprocessed by using the transformation functions to achieve the following: get the maximum square crop from the panel sample, grayscale the image (for uniformity, manhwas were also somehow part of the top rated manga list), apply horizontal flipping randomly, and resize each cropped panel to be compatible with the model I'm going to use later on. The entire dataset was split into training, validation, and testing sets.\n",
    "\n",
    "In this section, I also displayed **Table 1. Preview of Data Annotations.** to give you an idea of what the dataloader uses and plotted the histogram of the target variable - `rating`. You can observed below in **Figure 2. Distribution of Ratings** that since the list of mangas were limited to the top 5,000 rated series, the distribution of `rating`s seemingly follows the right-tail end of a bell curve.\n",
    "\n",
    "Finally, we also set a baseline value for an acceptable model's performance. I used the dataset's variance as the baseline. In effect, I'm going to compare the variability of the model's predictions against the inherent variability in the dataset.\n",
    "\n",
    "See <a href='https://github.com/jpK1ba/ManGanda/blob/master/utils/dataset.py'>code here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b77929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:31.778785Z",
     "start_time": "2023-06-29T13:18:31.723032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the built Dataset\n",
    "dataset = MangaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efccb5b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:31.852668Z",
     "start_time": "2023-06-29T13:18:31.780968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><style type=\"text/css\">\n",
       "#T_02675 th.col_heading {\n",
       "  background-color: black;\n",
       "  color: white;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_02675 td {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_02675 tr {\n",
       "  border-left: 1px solid black;\n",
       "  border-right: 1px solid black;\n",
       "  border-bottom: 1px solid black;\n",
       "}\n",
       "#T_02675 td {\n",
       "  border-left: 1px solid black;\n",
       "  border-right: 1px solid black;\n",
       "  border-bottom: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_02675\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_02675_level0_col0\" class=\"col_heading level0 col0\" >title</th>\n",
       "      <th id=\"T_02675_level0_col1\" class=\"col_heading level0 col1\" >rating</th>\n",
       "      <th id=\"T_02675_level0_col2\" class=\"col_heading level0 col2\" >paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row0_col0\" class=\"data row0 col0\" >Umi no Misaki</td>\n",
       "      <td id=\"T_02675_row0_col1\" class=\"data row0 col1\" >7.380000</td>\n",
       "      <td id=\"T_02675_row0_col2\" class=\"data row0 col2\" >./data/umi_no_misaki/umi_no_misaki_119_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row1_col0\" class=\"data row1 col0\" >Feng Shen Ji II</td>\n",
       "      <td id=\"T_02675_row1_col1\" class=\"data row1 col1\" >8.250000</td>\n",
       "      <td id=\"T_02675_row1_col2\" class=\"data row1 col2\" >./data/feng_shen_ji_ii/feng_shen_ji_ii_23_17.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row2_col0\" class=\"data row2 col0\" >Arifureta Shokugyou de Sekai Saikyou</td>\n",
       "      <td id=\"T_02675_row2_col1\" class=\"data row2 col1\" >7.710000</td>\n",
       "      <td id=\"T_02675_row2_col2\" class=\"data row2 col2\" >./data/arifureta_shokugyou_de_sekai_saikyou/arifureta_shokugyou_de_sekai_saikyou_23_12.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row3_col0\" class=\"data row3 col0\" >The Boxer</td>\n",
       "      <td id=\"T_02675_row3_col1\" class=\"data row3 col1\" >8.420000</td>\n",
       "      <td id=\"T_02675_row3_col2\" class=\"data row3 col2\" >./data/the_boxer/the_boxer_76_67.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row4_col0\" class=\"data row4 col0\" >Wotaku ni Koi wa Muzukashii</td>\n",
       "      <td id=\"T_02675_row4_col1\" class=\"data row4 col1\" >8.370000</td>\n",
       "      <td id=\"T_02675_row4_col2\" class=\"data row4 col2\" >./data/wotaku_ni_koi_wa_muzukashii/wotaku_ni_koi_wa_muzukashii_15_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row5_col0\" class=\"data row5 col0\" >Madou no Keifu</td>\n",
       "      <td id=\"T_02675_row5_col1\" class=\"data row5 col1\" >7.380000</td>\n",
       "      <td id=\"T_02675_row5_col2\" class=\"data row5 col2\" >./data/madou_no_keifu/madou_no_keifu_9_19.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row6_col0\" class=\"data row6 col0\" >Noragami</td>\n",
       "      <td id=\"T_02675_row6_col1\" class=\"data row6 col1\" >8.400000</td>\n",
       "      <td id=\"T_02675_row6_col2\" class=\"data row6 col2\" >./data/noragami/noragami_23_24.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row7_col0\" class=\"data row7 col0\" >Eureka Seven</td>\n",
       "      <td id=\"T_02675_row7_col1\" class=\"data row7 col1\" >7.700000</td>\n",
       "      <td id=\"T_02675_row7_col2\" class=\"data row7 col2\" >./data/eureka_seven/eureka_seven_19_20.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row8_col0\" class=\"data row8 col0\" >Yoroshiku Master</td>\n",
       "      <td id=\"T_02675_row8_col1\" class=\"data row8 col1\" >7.390000</td>\n",
       "      <td id=\"T_02675_row8_col2\" class=\"data row8 col2\" >./data/yoroshiku_master/yoroshiku_master_11_20.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_02675_row9_col0\" class=\"data row9 col0\" >Fantasy Bishoujo Juniku Ojisan to</td>\n",
       "      <td id=\"T_02675_row9_col1\" class=\"data row9 col1\" >7.510000</td>\n",
       "      <td id=\"T_02675_row9_col2\" class=\"data row9 col2\" >./data/fantasy_bishoujo_juniku_ojisan_to/fantasy_bishoujo_juniku_ojisan_to_42_4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"table1\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                           font-style:default;\">\n",
       "            <b>Table 1.</b> Preview of Data Annotations.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a preview of the annotations built\n",
    "toc.add_table(dataset.annotations.sample(10)[['title', 'rating', 'paths']],\n",
    "              'Data Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4b1a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:32.068150Z",
     "start_time": "2023-06-29T13:18:31.855184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure2.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig2\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 2.</b> Distribution of Ratings.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ratings(dataset, toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c6666e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:32.074896Z",
     "start_time": "2023-06-29T13:18:32.070125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>An acceptable model performance will be MSE < 0.3987.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = get_baseline(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223f06b",
   "metadata": {},
   "source": [
    "For the `MangaDataloader`, I've noticed that there were outliers in the dataset - which are valid images but made up mostly of blank spaces or white pixels. To mitigate this, I defined my own `collate_fn` to check wether the loaded image's characterestics lie within the distrution of my training dataset and reject loading it if found to be out of distribution.\n",
    "\n",
    "See <a href='https://github.com/jpK1ba/ManGanda/blob/master/utils/dataloader.py'>code here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2333cbee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:32.105062Z",
     "start_time": "2023-06-29T13:18:32.076911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the built Dataloader\n",
    "dataloader = MangaDataloader(dataset, batch_size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cea50b",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        ManGanda Model\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "To maximize my model's performance, I used a method called `Transfer Learning` which leverages a pre-trained, typically State-of-the-Art, model's learned representations or parameters as a starting point, improving the performance and efficiency of a model. For `Transfer Learning`, choosing a suitable pretrained model with, ideally, domain similarity is crucial to utilize its trained capabilities as transferrable knowledge. With that in mind, I employed a ResNet18 model - pretrained on the Danbooru2018 dataset, developed by Matthew Baas. Danbooru2018 consists of millions of annotated images collected from the Danbooru community, a popular imageboard site for anime and manga enthusiasts. If you want to know more about the pretrained model, you visit Matthew Baas's repository: https://github.com/RF5/danbooru-pretrained. [1]\n",
    "\n",
    "With the given domain similiraty and relatively smaller dataset, `Feature Extraction` is the best approach. [2] `Feature Extraction` is a type of `Transfer Learning` method that involves using the pretrained model to extract relevant features from the target data and then using these features as input to a separate model for a specific task, i.e. regression.\n",
    "\n",
    "MangaModel uses the pretrained ResNet18 model and initializes it with my saved and trained Regression network parameters. For my regression network, I added a threshold to discourage the model from sacrificing performance for certain datapoints to achieve lower over-all loss and consequently resulting in poor generalizability.\n",
    "\n",
    "See <a href='https://github.com/jpK1ba/ManGanda/blob/master/utils/manganda.py'>code here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a01b437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:18:33.457186Z",
     "start_time": "2023-06-29T13:18:32.106985Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/msds2023/jfabrero/.cache/torch/hub/RF5_danbooru-pretrained_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 112, 112]        (9,408)\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 112, 112]        (128)\n",
      "|    └─ReLU: 2-3                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 56, 56]          --\n",
      "|    └─Sequential: 2-5                   [-1, 64, 56, 56]          --\n",
      "|    |    └─BasicBlock: 3-1              [-1, 64, 56, 56]          (73,984)\n",
      "|    |    └─BasicBlock: 3-2              [-1, 64, 56, 56]          (73,984)\n",
      "|    └─Sequential: 2-6                   [-1, 128, 28, 28]         --\n",
      "|    |    └─BasicBlock: 3-3              [-1, 128, 28, 28]         (230,144)\n",
      "|    |    └─BasicBlock: 3-4              [-1, 128, 28, 28]         (295,424)\n",
      "|    └─Sequential: 2-7                   [-1, 256, 14, 14]         --\n",
      "|    |    └─BasicBlock: 3-5              [-1, 256, 14, 14]         (919,040)\n",
      "|    |    └─BasicBlock: 3-6              [-1, 256, 14, 14]         (1,180,672)\n",
      "|    └─Sequential: 2-8                   [-1, 512, 7, 7]           --\n",
      "|    |    └─BasicBlock: 3-7              [-1, 512, 7, 7]           (3,673,088)\n",
      "|    |    └─BasicBlock: 3-8              [-1, 512, 7, 7]           (4,720,640)\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─AdaptiveConcatPool2d: 2-9         [-1, 1024, 1, 1]          --\n",
      "|    |    └─AdaptiveMaxPool2d: 3-9       [-1, 512, 1, 1]           --\n",
      "|    |    └─AdaptiveAvgPool2d: 3-10      [-1, 512, 1, 1]           --\n",
      "|    └─Flatten: 2-10                     [-1, 1024]                --\n",
      "|    └─BatchNorm1d: 2-11                 [-1, 1024]                2,048\n",
      "|    └─Dropout: 2-12                     [-1, 1024]                --\n",
      "|    └─Linear: 2-13                      [-1, 512]                 524,800\n",
      "|    └─ReLU: 2-14                        [-1, 512]                 --\n",
      "|    └─BatchNorm1d: 2-15                 [-1, 512]                 1,024\n",
      "|    └─Dropout: 2-16                     [-1, 512]                 --\n",
      "|    └─Linear: 2-17                      [-1, 1]                   513\n",
      "|    └─Threshold: 2-18                   [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 11,704,897\n",
      "Trainable params: 528,385\n",
      "Non-trainable params: 11,176,512\n",
      "Total mult-adds (G): 1.83\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 35.23\n",
      "Params size (MB): 44.65\n",
      "Estimated Total Size (MB): 80.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "ManGanda = MangaModel(dataset, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54612c7f",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Evaluation\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "Now that the modelling is done, I'm going to evaluate my ManGanda model's performance and compare it against the previously defined baseline. The imported utility function `eval_model` does that for us.\n",
    "\n",
    "Lastly, to visualize what the model \"sees\" and display how it's performing for different manga series, I used `plot_predictions` to randomly select manga, get random samples, feed it into the model, and compare the predictions with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c80b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:21:14.861399Z",
     "start_time": "2023-06-29T13:18:33.462604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Test MSE Loss - 0.15<br> Baseline - 0.40<br><br>----------------------------------------------------------------<br>ManGanda is performing better than the set baseline!<br><br><br>****************************************************************<br>Other Metrics:<br>Test MAE Loss - 0.30<br></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_model(ManGanda, dataloader, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af57b79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:21:18.127241Z",
     "start_time": "2023-06-29T13:21:14.866026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure3.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig3\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 3.</b> Sample Prediction # 1 - The Pale Horse.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><b>Average Model Prediction - 7.70<br>   Actual Rating - 7.63</b><center><br><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure4.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig4\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 4.</b> Sample Prediction # 2 - Shitsuji-sama no Okiniiri.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><b>Average Model Prediction - 7.65<br>   Actual Rating - 7.89</b><center><br><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure5.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig5\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 5.</b> Sample Prediction # 3 - Haigakura.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><b>Average Model Prediction - 7.70<br>   Actual Rating - 7.35</b><center><br><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(ManGanda, dataset, toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8daf74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "Using different techniques for handling images, ManGanda was born. As evaluated using a test set, the model was able to achieve Test MSE of $0.16$ and Test MAE of $0.31$. With this, ManGanda is able to perform well enough to predict manga ratings, off only by $\\pm0.31$ on average.\n",
    "\n",
    "At first glance, this is already significant, however, I noticed that the model's predictions are seemingly bounded in a small range of values. To illustrate this, I made the function `plot_test` to plot the actual and predicted test ratings, see **Figure  6. Distribution of Test Ratings (True vs Predicted).**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63abfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:23:32.064670Z",
     "start_time": "2023-06-29T13:21:18.129327Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure6.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig6\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 6.</b> Distribution of Test Ratings (True vs Predicted).\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_test(ManGanda, dataloader, toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeacaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Explainability\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "It's my intuition the model learned the `mean rating` of the mangas as its bias for the last linear layer and that the incremental values are caused by the visual element it finds in the fed sample panels.\n",
    "\n",
    "As we've already seen what the model \"sees\", I'm now going to visualize what the model \"looks at\" using a technique called GradCAM. [3] GradCAM, short for Gradient-weighted Class Activation Mapping, is a technique that essentially provides a heat map visualization highlighting the regions of the image that contribute the most to the model's prediction. Grad-CAM is commonly used for classification tasks but in this use case, I'm using it to emphasizes the visual areas that influences my model.\n",
    "\n",
    "With GradCAM, it can be interpretted that the cool spots (blue) affect the predicted rating minimally and that hot spots (red) are the areas that drive the prediction the most. This is visualized below in **Figure 7. GradCAM Implementation - \\<Manga Title>**.\n",
    "\n",
    "See <a href='https://github.com/jpK1ba/ManGanda/blob/master/utils/mangagradcam.py'>code here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36594aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T13:23:34.739520Z",
     "start_time": "2023-06-29T13:23:32.067354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure7.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig7\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 7.</b> GradCAM Implementation - P to JK.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ManGandaCAM = MangaGradCAM(ManGanda)\n",
    "plot_saliencies(ManGandaCAM, ManGanda, toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0042b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Conclusion\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "What a blast, definitely had fun with this project. Started from building my own dataset by Web Scraping. Building custom Datasets and Dataloaders using Pytorch. Finally, proceeded to retraining a Pretrained ResNET model and coming up with ManGanda. It's best predictive performance so far is off only by $\\pm0.31$ on average. Although the performance of the model seem satisfactory, it still have some room for improvement. Ultimately, ManGanda further leveraged XAI in cracking down the key visual elements with hope to guide artists of what works or don't.\n",
    "\n",
    "All the codes are linked to avoid cluttering this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed22099b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        References\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "[1] Matthew Baas. (2019). Danbooru2018 pretrained resnet models for PyTorch. GitHub. https://github.com/RF5/danbooru-pretrained\n",
    "\n",
    "[2] Elgendy, M. (2020, November 10). Deep Learning for Vision Systems. Manning Publications Co.\n",
    "\n",
    "[3] Selvaraju, Ramprasaath R., Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. “Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.” 2017 (October 2017): 618–626, https://doi.org/10.1109/ICCV.2017.74."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "185.625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
