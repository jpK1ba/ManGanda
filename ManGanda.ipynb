{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b34282",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h1 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:50px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        ManGanda\n",
    "    </h1>\n",
    "***\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Regressive Approach in Rating Mangas thru Sample Art\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "by : JP Fabrero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f70d2",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Introduction\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "We're diving into the marvelous world of manga, where things have been blowing up like never before. With its origins in Japan, manga has transcended cultural boundaries and captivated readers of all ages and backgrounds. It's a multidimensional art form, encompassing storytelling, character development, pacing, thematic depth, and stunning art.\n",
    "\n",
    "Now, here's the thing: with the manga industry booming and countless series hitting the shelves every day, it can be a real challenge to figure out which ones are worth your time and money. That's where ManGanda comes in. It's on a mission to help both publishers and readers make better-informed decisions about which manga series to invest in and promote.\n",
    "\n",
    "We'll take out all the literary elements of a manga and take a close look at the key visual and storytelling elements that make a manga shine. This approach is all about that art style, character design, and panel composition. By analyzing these factors, ManGanda aims and attempts to provide a sneak peek of a manga's potential rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b06c3b",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Methodology\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "The implementation of this model is pretty straight-forward. The biggest challenge is building up the custom dataset and defining the mechanism for dataloader. Used Transer Learning for impact and performance. This is a run-down of the steps made towards ManGanda's goals.\n",
    "\n",
    "* Data Collection and Annotation:\n",
    "    - Obtain a list of top-rated manga titles and their corresponding ratings as ground labels from MangaList: https://myanimelist.net/topmanga.php?type=manga.\n",
    "    - Using the obtained list of mangas, download availabel manga panel samples from MangaFreak, https://w15.mangafreak.net/, to create a diverse dataset representing a wide range of art styles and genres.\n",
    "    - Create an annotations library that includes file paths, ratings, and titles for each panel sample, establishing a mapping between the panel images and their associated manga ratings.\n",
    "<br></br>\n",
    "* Data Preprocessing and EDA:\n",
    "    - Utilize the Torch library to create custom datasets.\n",
    "    - Preprocess the panel samples by using the transformation functions and achieve the following: get the maximum square crop from the panel, grayscaled image samples, randomly, horizontally flips samples, and resized panels compatible with the ResNet model.\n",
    "    - Split the annotated dataset into training, validation, and testing sets in preparation for training and evaluation.\n",
    "<br></br>\n",
    "* Dataloader Customization:\n",
    "    - Utilize the Torch library to create dataloaders.\n",
    "    - Employed a simple outlier detection mechanism in the collate function to reject loading outliers found in the loaded data.\n",
    "<br></br>\n",
    "* Pretrained Model Selection:\n",
    "    - For transfer learning, choosing a suitable pretrained model is crucial to leverage its trained capabilities and powerful feature extraction. In this case, employ the pretrained ResNet18 model trained on the Danbooru2018 dataset, developed by Matthew Baas. Danbooru2018 consists of millions of annotated images collected from the Danbooru community, a popular imageboard site for anime and manga enthusiasts.[3]\n",
    "<br></br>\n",
    "* Model Modification and Training:\n",
    "    - Adapt the selected pretrained model for regression application, as the goal is to predict manga ratings.\n",
    "    - Replace the final classification layer of the ResNet18 model with a custom regression layer that outputs a continuous value representing the predicted rating.\n",
    "    - Employ a suitable loss function, mean squared error (MSE), to measure the disparity between predicted ratings and ground truth ratings.\n",
    "    - Perform model training using Adam algorithm to optimize and update the model parameters and minimize the loss.\n",
    "<br></br>\n",
    "* Model Evaluation:\n",
    "     - Evaluate and apply the trained ManGanda model to predict the ratings of new manga panel samples and assess its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918f0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Importing Libraries\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd9b145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.185852Z",
     "start_time": "2023-06-12T15:21:14.190737Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SKIMAGE_DATADIR'] = '/tmp/.skimage_cache'\n",
    "os.environ['XDG_CACHE_HOME'] = '/home/msds2023/jfabrero/.cache'\n",
    "\n",
    "import re, time, shutil, copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import  urllib.parse as urlp\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from pyjanitor import auto_toc\n",
    "from pickling import *\n",
    "toc = auto_toc()\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31afa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Data Collection and Annotation\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "Contains functions to collect mangalist and manga sample panels. See code runs for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f0b5d",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467968b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.201989Z",
     "start_time": "2023-06-12T15:21:17.189310Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attrs(url):\n",
    "    \"\"\"Get titles, urls, and ratings in the rankings page\"\"\"\n",
    "    soup = bs4.BeautifulSoup(requests.get(url).content)\n",
    "    mangas = soup.select('tr[class=\"ranking-list\"]')\n",
    "    \n",
    "    # Titles\n",
    "    titles = [\n",
    "        manga.select_one('h3[class=\"manga_h3\"]').text for manga in mangas\n",
    "    ]\n",
    "    \n",
    "    # URLs\n",
    "    urls = [\n",
    "        manga.select_one('h3[class=\"manga_h3\"] a').get('href') \n",
    "        for manga in mangas\n",
    "    ]\n",
    "    \n",
    "    # Ratings\n",
    "    ratings = [\n",
    "        float(manga.select_one('td[class=\"score ac fs14\"]').text.strip())\n",
    "        for manga in mangas\n",
    "    ]\n",
    "    \n",
    "    # Check Results\n",
    "    if not len(titles) == len(urls) == len(ratings):\n",
    "        raise Error\n",
    "    \n",
    "    return titles, urls, ratings\n",
    "\n",
    "\n",
    "def get_details(url):\n",
    "    \"\"\"Get n_faves, genres, and authors in the manga page\"\"\"\n",
    "    soup = bs4.BeautifulSoup(requests.get(url).content)\n",
    "    \n",
    "    # Number of Favorites\n",
    "    try:\n",
    "        n_fav = [list(n_fav.parent.children)[1].text\n",
    "                 for n_fav in soup.select('div[class=\"spaceit_pad\"] span')\n",
    "                 if n_fav.text == 'Favorites:'][0]\n",
    "        n_fav = int(re.sub(r'\\D', '', n_fav))\n",
    "    except:\n",
    "        n_fav = None\n",
    "    \n",
    "    # Genre\n",
    "    try:\n",
    "        genre = [genre.text for genre in \n",
    "                 soup.select('div[class=\"spaceit_pad\"]'\n",
    "                             ' span[itemprop=\"genre\"]')\n",
    "                 if genre.parent.select_one('span').text == 'Genres:']\n",
    "    except:\n",
    "        genre = []\n",
    "    \n",
    "    # Authors\n",
    "    try:\n",
    "        author = [author.text for author in \n",
    "                  soup.select('div[class=\"spaceit_pad\"] a')\n",
    "                  if author.parent.select_one('span').text == 'Authors:']\n",
    "    except:\n",
    "        author = []\n",
    "        \n",
    "    return n_fav, genre, author\n",
    "\n",
    "\n",
    "def get_data(limit):\n",
    "    \"\"\"Crawl `myanimelist.net` for the list of mangas and details\"\"\"\n",
    "    # Load data if available\n",
    "    try:\n",
    "        df = load_pkl(f'df_{limit}')\n",
    "        \n",
    "    except:\n",
    "        # Instatiate Features\n",
    "        titles  = []\n",
    "        urls    = []\n",
    "        ratings = []\n",
    "\n",
    "        # Crawl Ranking Pages (https://myanimelist.net/topmanga.php?limit=0)\n",
    "        for start in trange(0,limit,50):\n",
    "            url = f'https://myanimelist.net/topmanga.php?limit={start}'\n",
    "            try:\n",
    "                results = get_attrs(url)\n",
    "            except:\n",
    "                print(f'Crawling Ended Prematurely, Stopped @ {start}')\n",
    "                break\n",
    "\n",
    "            # Update\n",
    "            titles.extend(results[0])\n",
    "            urls.extend(results[1])\n",
    "            ratings.extend(results[2])\n",
    "\n",
    "        # Instatiate Other Details\n",
    "        n_favs  = []\n",
    "        genres  = []\n",
    "        authors = []\n",
    "\n",
    "        # Scrape each Manga Page (https://myanimelist.net/manga/2/Berserk)\n",
    "        for url in tqdm(urls):\n",
    "            details = get_details(url)\n",
    "\n",
    "            # Update\n",
    "            n_favs.append(details[0])\n",
    "            genres.append(details[1])\n",
    "            authors.append(details[2])\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'titles': titles,\n",
    "            'urls': urls,\n",
    "            'ratings': ratings,\n",
    "            'n_favs': n_favs,\n",
    "            'genres': genres,\n",
    "            'authors': authors,\n",
    "        })\n",
    "        save_pkl(df, f'df_{limit}')\n",
    "        df.to_csv(f'df_{limit}.csv', index=False)\n",
    "                 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50fe283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.222025Z",
     "start_time": "2023-06-12T15:21:17.204127Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_samples(title, n=3):\n",
    "    \"\"\"Download manga pages\"\"\"\n",
    "    # Format title\n",
    "    title_url = re.sub(r'\\W', '_', title.title())\n",
    "    url = f'https://w15.mangafreak.net/Read1_{title_url}_1'\n",
    "    soup = bs4.BeautifulSoup(requests.get(url, timeout=2).content)\n",
    "    \n",
    "    # Check if manga is found\n",
    "    home_title = 'Read Free Manga Online - MangaFreak'\n",
    "    if soup.select_one('title').text == home_title:\n",
    "        return False # Skip if not\n",
    "        \n",
    "    else:\n",
    "        # Check for folder\n",
    "        if not os.path.exists(f'./data/{title_url.lower()}'):\n",
    "            os.mkdir(f'./data/{title_url.lower()}')\n",
    "        \n",
    "        # Check for contents\n",
    "        if len(os.listdir(f'./data/{title_url.lower()}')) < 5*n:\n",
    "\n",
    "            # Get Chapters\n",
    "            chapters = [re.findall(r'_(\\d+)', chapter.get('value'))[0]\n",
    "                        for chapter in soup.select('option')\n",
    "                        if 'Read1' in chapter.get('value')]\n",
    "\n",
    "            # Remove folder if no valid chapters\n",
    "            if len(set(chapters)) < 5:\n",
    "                shutil.rmtree(f'./data/{title_url.lower()}',\n",
    "                              ignore_errors=True)\n",
    "                return False\n",
    "\n",
    "            # Get Random Chapters\n",
    "            for chapter in np.random.choice(chapters, 5, replace=False):\n",
    "                c_url = (f'https://w15.mangafreak.net/'\n",
    "                         f'Read1_{title_url}_{chapter}')\n",
    "                chap_soup = bs4.BeautifulSoup(\n",
    "                    requests.get(c_url, timeout=2).content\n",
    "                )\n",
    "\n",
    "                # Get Number of Pages\n",
    "                try:\n",
    "                    pages = int(re.findall(r'(\\d+) pages',\n",
    "                                           chap_soup.text)[0])\n",
    "                except:\n",
    "                    try:\n",
    "                        pages = int([re.findall(r'Page (\\d+)',\n",
    "                                                page.get('alt'))[0]\n",
    "                                     for page in chap_soup.select('img')\n",
    "                                     if 'Page' in page.get('alt')][-1])\n",
    "                    except:\n",
    "                        pages = 10\n",
    "\n",
    "                title_lower = title_url.lower()\n",
    "\n",
    "                # Download images\n",
    "                half = pages // 2\n",
    "\n",
    "                for page in range(half-int(n/2), half+round(n/2)):\n",
    "                    url = (f'https://images.mangafreak.net/mangas'\n",
    "                           f'/{title_lower}/{title_lower}_{chapter}'\n",
    "                           f'/{title_lower}_{chapter}_{page}.jpg')\n",
    "                    !wget -q '{url}' -P './data/{title_lower}' \n",
    "    \n",
    "    # If all is successful\n",
    "    return True\n",
    "\n",
    "def download_mangas(df, n=3):\n",
    "    \"\"\"Download images samples for the listed mangas\"\"\"\n",
    "    # Create folder for data\n",
    "    if not os.path.exists('./data'):\n",
    "        os.mkdir('./data')\n",
    "    \n",
    "        # Get list of mangas with downloadable images\n",
    "        mangas = []\n",
    "\n",
    "        # For each manga\n",
    "        for title in tqdm(df['titles'].tolist()):\n",
    "\n",
    "            try:\n",
    "                # Download samples\n",
    "                if download_samples(title, n=3):\n",
    "                    # Append the title to mangas if filled with images\n",
    "                    mangas.append(title)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Get the relevant mangas\n",
    "        df['check'] = (\n",
    "            df['titles'].apply(lambda x: re.sub(r'\\W', '_', x.lower()))\n",
    "        )\n",
    "        df.set_index('titles', inplace=True)\n",
    "\n",
    "        df_manga = df.loc[mangas]\n",
    "\n",
    "        print('Downloading Samples: Success!')\n",
    "        \n",
    "    else:\n",
    "        mangas = os.listdir('./data')\n",
    "        \n",
    "        df['check'] = (\n",
    "            df['titles'].apply(lambda x: re.sub(r'\\W', '_', x.lower()))\n",
    "        )\n",
    "        df = df.sort_values('ratings').drop_duplicates('titles', keep='last')\n",
    "        df.set_index('titles', inplace=True)\n",
    "        df_manga = df[df['check'].isin(mangas)]\n",
    "        \n",
    "        print('Samples are already downloaded!')\n",
    "    \n",
    "    print(f'Download Rate: {(len(df_manga)/len(df)*100):.2f}%')\n",
    "    return df_manga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47577eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.232024Z",
     "start_time": "2023-06-12T15:21:17.224960Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metadata(df_data):\n",
    "    \"\"\"Get annotations for dataset\"\"\"\n",
    "    if os.path.exists('metadata.csv'):\n",
    "        pass\n",
    "    else:\n",
    "        df_data = df_data.reset_index().set_index('check')\n",
    "\n",
    "        data_dir = './data'\n",
    "        mangas = os.listdir(data_dir)\n",
    "\n",
    "\n",
    "        df_metadata = pd.DataFrame()\n",
    "        for manga in mangas:\n",
    "            if manga[0] == '.':\n",
    "                continue\n",
    "            manga_path = os.path.join(data_dir, manga)\n",
    "            paths = [os.path.join(manga_path, x)\n",
    "                     for x in os.listdir(manga_path)]\n",
    "\n",
    "            # Check data\n",
    "            verified = []\n",
    "            for path in paths:\n",
    "                try:\n",
    "                    transforms.ToTensor()(Image.open(path))\n",
    "                    verified.append(path)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # Save good data\n",
    "            df_manga = pd.DataFrame({'paths': verified})\n",
    "            df_manga['rating'] = [df_data.loc[manga, 'ratings']]*len(verified)\n",
    "            df_manga['title'] = [df_data.loc[manga, 'titles']]*len(verified)\n",
    "\n",
    "            df_metadata = pd.concat([df_metadata, df_manga])\n",
    "\n",
    "        df_metadata.to_csv('metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b73af",
   "metadata": {},
   "source": [
    "#### Code Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079052d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.243143Z",
     "start_time": "2023-06-12T15:21:17.234020Z"
    }
   },
   "outputs": [],
   "source": [
    "df_top = get_data(5_000) # Top 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3feca440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.267069Z",
     "start_time": "2023-06-12T15:21:17.245132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are already downloaded!\n",
      "Download Rate: 25.65%\n"
     ]
    }
   ],
   "source": [
    "df_dl = download_mangas(df_top) # Dataframe of sampled manga details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247bf381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.272966Z",
     "start_time": "2023-06-12T15:21:17.269185Z"
    }
   },
   "outputs": [],
   "source": [
    "get_metadata(df_dl) # Write annotations based from sampled mangas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db44e5",
   "metadata": {},
   "source": [
    "#### Section Notes\n",
    "\n",
    "* *Limited the list of mangas to only the top 5,000 highly rated mangas in `mangalist`*\n",
    "* *Only sampled mangas available in the `mangafreak` website. Sampling was done by choosing random chapters and getting the panels near the middle in order to avoid colored covers.*\n",
    "* *Handled duplicates in the manga lists. Retained the higher available rating.*\n",
    "* *Skipped corrupted image files.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e2fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Data Preprocessing and EDA\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "Contains functions for customizing the dataset and printing out analysis on data. See code runs for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad6af1",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7625118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.283503Z",
     "start_time": "2023-06-12T15:21:17.275062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Manga Dataset\n",
    "class MangaDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for mangas\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Get annotations of mangas\"\"\"\n",
    "        self.metadata = pd.read_csv('metadata.csv')\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get manga item and apply preset transformations\"\"\"\n",
    "        path = self._get_manga_path(index)\n",
    "        label = self._get_manga_label(index)\n",
    "        title = self._get_manga_title(index)\n",
    "        \n",
    "        image = transforms.ToTensor()(Image.open(path))\n",
    "        if image.shape[0] == 1:\n",
    "            image = image.repeat(3, 1, 1)\n",
    "\n",
    "        dim = min(torch.tensor(image.shape[1:])).item()\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.CenterCrop(dim),\n",
    "            transforms.Resize(224, antialias=True),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "        ])\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, label, path, title\n",
    "\n",
    "    def _get_manga_path(self, index):\n",
    "        return self.metadata.iloc[index, 0]\n",
    "\n",
    "    def _get_manga_label(self, index):\n",
    "        return self.metadata.iloc[index, 1]\n",
    "    \n",
    "    def _get_manga_title(self, index):\n",
    "        return self.metadata.iloc[index, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436a021e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.290780Z",
     "start_time": "2023-06-12T15:21:17.285820Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_ratings(dataset):\n",
    "    \"\"\"Plot the histogram of ratings\"\"\"\n",
    "    plot = (\n",
    "        dataset.metadata\n",
    "        .groupby(['title'])['rating'].mean()\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    ax.hist(plot, bins=60, color='k', alpha=0.8)\n",
    "    ax.set_ylabel('Number of Mangas')\n",
    "    ax.set_xlabel('Ratings')\n",
    "    toc.add_fig('Distribution of Ratings', width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8c8def",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.300401Z",
     "start_time": "2023-06-12T15:21:17.295859Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_baseline(dataset):\n",
    "    \"\"\"Print the baseline value to beat\"\"\"\n",
    "    baseline = dataset.metadata.rating.std()\n",
    "\n",
    "    display(HTML(\n",
    "        f'<b>An acceptable model performance will be MSE < '\n",
    "        f'{baseline:0.4f}.</b>'\n",
    "    ))\n",
    "    \n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88e714",
   "metadata": {},
   "source": [
    "#### Code Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b77929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.327245Z",
     "start_time": "2023-06-12T15:21:17.302926Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MangaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efccb5b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.388467Z",
     "start_time": "2023-06-12T15:21:17.329372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><style type=\"text/css\">\n",
       "#T_226e6 th.col_heading {\n",
       "  background-color: black;\n",
       "  color: white;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_226e6 tr {\n",
       "  border-left: 1px solid black;\n",
       "  border-right: 1px solid black;\n",
       "  border-bottom: 1px solid black;\n",
       "}\n",
       "#T_226e6 td {\n",
       "  border-left: 1px solid black;\n",
       "  border-right: 1px solid black;\n",
       "  border-bottom: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_226e6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_226e6_level0_col0\" class=\"col_heading level0 col0\" >paths</th>\n",
       "      <th id=\"T_226e6_level0_col1\" class=\"col_heading level0 col1\" >rating</th>\n",
       "      <th id=\"T_226e6_level0_col2\" class=\"col_heading level0 col2\" >title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row0_col0\" class=\"data row0 col0\" >./data/denpa_kyoushi/denpa_kyoushi_43_10.jpg</td>\n",
       "      <td id=\"T_226e6_row0_col1\" class=\"data row0 col1\" >7.660000</td>\n",
       "      <td id=\"T_226e6_row0_col2\" class=\"data row0 col2\" >Denpa Kyoushi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row1_col0\" class=\"data row1 col0\" >./data/fantasista/fantasista_56_9.jpg</td>\n",
       "      <td id=\"T_226e6_row1_col1\" class=\"data row1 col1\" >7.650000</td>\n",
       "      <td id=\"T_226e6_row1_col2\" class=\"data row1 col2\" >Fantasista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row2_col0\" class=\"data row2 col0\" >./data/shuukan_shounen_hachi/shuukan_shounen_hachi_4_11.jpg</td>\n",
       "      <td id=\"T_226e6_row2_col1\" class=\"data row2 col1\" >7.280000</td>\n",
       "      <td id=\"T_226e6_row2_col2\" class=\"data row2 col2\" >Shuukan Shounen Hachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row3_col0\" class=\"data row3 col0\" >./data/hidamari_ga_kikoeru/hidamari_ga_kikoeru_4_17.jpg</td>\n",
       "      <td id=\"T_226e6_row3_col1\" class=\"data row3 col1\" >8.180000</td>\n",
       "      <td id=\"T_226e6_row3_col2\" class=\"data row3 col2\" >Hidamari ga Kikoeru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row4_col0\" class=\"data row4 col0\" >./data/boku_no_hero_academia/boku_no_hero_academia_111_10.jpg</td>\n",
       "      <td id=\"T_226e6_row4_col1\" class=\"data row4 col1\" >8.110000</td>\n",
       "      <td id=\"T_226e6_row4_col2\" class=\"data row4 col2\" >Boku no Hero Academia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row5_col0\" class=\"data row5 col0\" >./data/ojojojo/ojojojo_54_2.jpg</td>\n",
       "      <td id=\"T_226e6_row5_col1\" class=\"data row5 col1\" >7.470000</td>\n",
       "      <td id=\"T_226e6_row5_col2\" class=\"data row5 col2\" >Ojojojo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row6_col0\" class=\"data row6 col0\" >./data/spirit_fingers/spirit_fingers_72_16.jpg</td>\n",
       "      <td id=\"T_226e6_row6_col1\" class=\"data row6 col1\" >8.220000</td>\n",
       "      <td id=\"T_226e6_row6_col2\" class=\"data row6 col2\" >Spirit Fingers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row7_col0\" class=\"data row7 col0\" >./data/livingstone/livingstone_10_15.jpg</td>\n",
       "      <td id=\"T_226e6_row7_col1\" class=\"data row7 col1\" >7.430000</td>\n",
       "      <td id=\"T_226e6_row7_col2\" class=\"data row7 col2\" >Livingstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row8_col0\" class=\"data row8 col0\" >./data/nobunaga_no_chef/nobunaga_no_chef_47_10.jpg</td>\n",
       "      <td id=\"T_226e6_row8_col1\" class=\"data row8 col1\" >7.740000</td>\n",
       "      <td id=\"T_226e6_row8_col2\" class=\"data row8 col2\" >Nobunaga no Chef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_226e6_row9_col0\" class=\"data row9 col0\" >./data/dantalian_no_shoka/dantalian_no_shoka_23_19.jpg</td>\n",
       "      <td id=\"T_226e6_row9_col1\" class=\"data row9 col1\" >7.500000</td>\n",
       "      <td id=\"T_226e6_row9_col2\" class=\"data row9 col2\" >Dantalian no Shoka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <center style=\"font-size:14px;\n",
       "                           font-style:default;\">\n",
       "            <b>Table 1.</b> Preview of Data Annotations.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toc.add_table(dataset.metadata.sample(10),\n",
    "              'Data Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4b1a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.617572Z",
     "start_time": "2023-06-12T15:21:17.390672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure1.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 1.</b> Distribution of Ratings.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ratings(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c6666e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.625978Z",
     "start_time": "2023-06-12T15:21:17.619847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>An acceptable model performance will be MSE < 0.3929.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = get_baseline(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3731450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.654291Z",
     "start_time": "2023-06-12T15:21:17.628657Z"
    }
   },
   "outputs": [],
   "source": [
    "stages = ['train', 'val', 'test']\n",
    "\n",
    "trainval, test = train_test_split(dataset.metadata.index.tolist(),\n",
    "                                  stratify=dataset.metadata.rating,\n",
    "                                  test_size=0.1,\n",
    "                                  random_state=143)\n",
    "train, val = train_test_split(trainval,\n",
    "                              stratify=dataset.metadata.loc[trainval].rating,\n",
    "                              test_size=1/6,\n",
    "                              random_state=143)\n",
    "\n",
    "# Size of datasets\n",
    "dataset_sizes = {}\n",
    "for stage in stages:\n",
    "    exec(f'dataset_sizes[\"{stage}\"] = len({stage})')\n",
    "\n",
    "# Subsetting of datasets for each stage/phase\n",
    "datasets = {}\n",
    "for stage in stages:\n",
    "    exec(f'datasets[\"{stage}\"] = Subset(dataset, {stage})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969cd72",
   "metadata": {},
   "source": [
    "#### Section Notes\n",
    "\n",
    "* *Since the list of mangas were limited to the top 5,00, the distribution of ratings seemingly follows the right-tail end of a bell curve*\n",
    "* *Added grayscaling transformation as added layer of ensuring uniformity.*\n",
    "* *Stratified the splitting in attempt to help training.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0439e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Dataloader Customization\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "Contains functions for collation and employing outlier detection. See code runs for implementation and instatiation of the dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77873b8a",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df862945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.662614Z",
     "start_time": "2023-06-12T15:21:17.656972Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Collating function for the dataset\"\"\"\n",
    "    X, Y = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for x, y, _, _ in batch:\n",
    "        \n",
    "        # Outlier Detection\n",
    "        if (x.mean().item() >= dataset._mean_thresh and \n",
    "            x.std().item() >= dataset._std_thresh):\n",
    "\n",
    "            X += [torch.tensor(x)]\n",
    "            Y += [torch.tensor(y)]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    X = torch.stack(X)\n",
    "    Y = torch.stack(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f54a0d",
   "metadata": {},
   "source": [
    "#### Code Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e6c7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.692694Z",
     "start_time": "2023-06-12T15:21:17.665122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting Training Distribution\n",
    "try:\n",
    "    means = load_pkl('means')\n",
    "    stds = load_pkl('stds')\n",
    "except:\n",
    "    means = []\n",
    "    stds = []\n",
    "    for img_t, *_ in datasets['train']:\n",
    "        means += [img_t.mean().item()]\n",
    "        stds += [img_t.std().item()]\n",
    "        \n",
    "dataset._mean_thresh = np.quantile(means, 0.01)\n",
    "dataset._std_thresh = np.quantile(stds, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24b76c56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:17.703360Z",
     "start_time": "2023-06-12T15:21:17.696980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building the DataLoader\n",
    "dataloaders = {}\n",
    "for stage in stages:\n",
    "    shuffle = stage != 'test'\n",
    "    exec(f\"\"\"dataloaders[\"{stage}\"] = DataLoader(datasets[\"{stage}\"],\n",
    "                                                 batch_size=24,\n",
    "                                                 shuffle={shuffle},\n",
    "                                                 collate_fn=collate_fn,\n",
    "                                                 num_workers=1)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055bce46",
   "metadata": {},
   "source": [
    "#### Section Notes\n",
    "\n",
    "* *Employed a simple Out-of-Distribution Detection and Rejection mechanism via collate function. The statistics were based from the training data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd073ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Pretrained Model Selection\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***\n",
    "Loading and downloading the pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd351a",
   "metadata": {},
   "source": [
    "#### Code Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a01b437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:18.703047Z",
     "start_time": "2023-06-12T15:21:17.706466Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/msds2023/jfabrero/.cache/torch/hub/RF5_danbooru-pretrained_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the device for loading the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instatiate the model\n",
    "model = torch.hub.load('RF5/danbooru-pretrained', 'resnet18',\n",
    "                       pretrained=False)\n",
    "\n",
    "# Load the pretrained weights\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "    'https://github.com/RF5/danbooru-pretrained/releases/download/v0.1/resnet18-3f77756f.pth',\n",
    "    map_location=device.type\n",
    ")\n",
    "state_dict = {key.replace(\"module.\", \"\"): value \n",
    "              for key, value in checkpoint.items()}\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74b629",
   "metadata": {},
   "source": [
    "#### Section Notes\n",
    "* *This model was chosen primarily due to its training with anime and manga images.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016daf6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Model Modification and Training\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69447636",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa99d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:18.728232Z",
     "start_time": "2023-06-12T15:21:18.706865Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    \"\"\"A simple training loop\"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1_000_000\n",
    "\n",
    "    for epoch in trange(num_epochs):\n",
    "        log = f'Epoch {epoch+1:2d}/{num_epochs}  |'\n",
    "        # Each epoch has a training and validation phase\n",
    "        for stage in ['train', 'val']:\n",
    "            if stage == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for X, y in tqdm(dataloaders[stage]):\n",
    "                X = X.to(device)\n",
    "                y = y.float().to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(stage == 'train'):\n",
    "                    out = model(X)\n",
    "                    loss = criterion(out, y)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if stage == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * X.size(0)\n",
    "           \n",
    "            epoch_loss = running_loss / dataset_sizes[stage]\n",
    "            \n",
    "            if stage == 'val':\n",
    "                stage = 'validation'\n",
    "            log += (f'  {stage.title()} Loss: {epoch_loss:.4f}  |')\n",
    "\n",
    "            # deep copy the model\n",
    "            if stage == 'validation' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(log)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m'\n",
    "          f'{time_elapsed % 60:.0f}s')\n",
    "    print(f'Best Validation Loss: {best_loss:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    torch.save(model.state_dict(), 'MangaModel.pth')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a3652",
   "metadata": {},
   "source": [
    "#### Code Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "708c616b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:18.819143Z",
     "start_time": "2023-06-12T15:21:18.733507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freezing the weights of the pretrained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad64add",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:18.920450Z",
     "start_time": "2023-06-12T15:21:18.826127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the Last Layer and adding linear layers\n",
    "model[1][8] = nn.Linear(512, 128)\n",
    "if len(model[1]) != 14:\n",
    "    model[1].append(nn.ReLU())\n",
    "    model[1].append(nn.Dropout(0.2))\n",
    "    model[1].append(nn.Linear(128, 32))\n",
    "    model[1].append(nn.ReLU())\n",
    "    model[1].append(nn.Linear(32, 1))\n",
    "    model[1].append(nn.Threshold(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72cb1f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:19.338782Z",
     "start_time": "2023-06-12T15:21:18.925627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 112, 112]        (9,408)\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 112, 112]        (128)\n",
      "|    └─ReLU: 2-3                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 56, 56]          --\n",
      "|    └─Sequential: 2-5                   [-1, 64, 56, 56]          --\n",
      "|    |    └─BasicBlock: 3-1              [-1, 64, 56, 56]          (73,984)\n",
      "|    |    └─BasicBlock: 3-2              [-1, 64, 56, 56]          (73,984)\n",
      "|    └─Sequential: 2-6                   [-1, 128, 28, 28]         --\n",
      "|    |    └─BasicBlock: 3-3              [-1, 128, 28, 28]         (230,144)\n",
      "|    |    └─BasicBlock: 3-4              [-1, 128, 28, 28]         (295,424)\n",
      "|    └─Sequential: 2-7                   [-1, 256, 14, 14]         --\n",
      "|    |    └─BasicBlock: 3-5              [-1, 256, 14, 14]         (919,040)\n",
      "|    |    └─BasicBlock: 3-6              [-1, 256, 14, 14]         (1,180,672)\n",
      "|    └─Sequential: 2-8                   [-1, 512, 7, 7]           --\n",
      "|    |    └─BasicBlock: 3-7              [-1, 512, 7, 7]           (3,673,088)\n",
      "|    |    └─BasicBlock: 3-8              [-1, 512, 7, 7]           (4,720,640)\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─AdaptiveConcatPool2d: 2-9         [-1, 1024, 1, 1]          --\n",
      "|    |    └─AdaptiveMaxPool2d: 3-9       [-1, 512, 1, 1]           --\n",
      "|    |    └─AdaptiveAvgPool2d: 3-10      [-1, 512, 1, 1]           --\n",
      "|    └─Flatten: 2-10                     [-1, 1024]                --\n",
      "|    └─BatchNorm1d: 2-11                 [-1, 1024]                (2,048)\n",
      "|    └─Dropout: 2-12                     [-1, 1024]                --\n",
      "|    └─Linear: 2-13                      [-1, 512]                 (524,800)\n",
      "|    └─ReLU: 2-14                        [-1, 512]                 --\n",
      "|    └─BatchNorm1d: 2-15                 [-1, 512]                 (1,024)\n",
      "|    └─Dropout: 2-16                     [-1, 512]                 --\n",
      "|    └─Linear: 2-17                      [-1, 128]                 65,664\n",
      "|    └─ReLU: 2-18                        [-1, 128]                 --\n",
      "|    └─Dropout: 2-19                     [-1, 128]                 --\n",
      "|    └─Linear: 2-20                      [-1, 32]                  4,128\n",
      "|    └─ReLU: 2-21                        [-1, 32]                  --\n",
      "|    └─Linear: 2-22                      [-1, 1]                   33\n",
      "|    └─Threshold: 2-23                   [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 11,774,209\n",
      "Trainable params: 69,825\n",
      "Non-trainable params: 11,704,384\n",
      "Total mult-adds (G): 1.83\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 35.24\n",
      "Params size (MB): 44.92\n",
      "Estimated Total Size (MB): 80.72\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Preview or summary of the modified model for regression\n",
    "details = summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a45c9084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:19.432348Z",
     "start_time": "2023-06-12T15:21:19.421780Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "# Set the loss function for Regression\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Only the parameters of the regressor are being optimized\n",
    "optimizer = optim.Adam(model[1].parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "548247aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:19.638290Z",
     "start_time": "2023-06-12T15:21:19.516411Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the retrained model, else, train\n",
    "try:\n",
    "    model.load_state_dict(torch.load('MangaModel_v2.pth'))\n",
    "    MangaModel = model\n",
    "except:\n",
    "    MangaModel = train_model(model, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5d225",
   "metadata": {},
   "source": [
    "#### Section Notes\n",
    "\n",
    "* *Minimized training cost by freezing most of the model weights and changing/appending linear layers*\n",
    "* *Added a threshold to discourage model from sacrificing certain datapoints to achieve lower loss, resulting in poor generalizability*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd56578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h3 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:22px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Model Evaluation\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "Contains functions to print out evaluation metrics and sample ratings. See code runs for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a50e2a",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19235b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:19.735895Z",
     "start_time": "2023-06-12T15:21:19.720623Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(model, baseline):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    mse = 0.0\n",
    "    mae = nn.L1Loss()\n",
    "    mae_losses = 0.0\n",
    "    \n",
    "    # Iterate over data.\n",
    "    for X, y in tqdm(dataloaders['test']):\n",
    "        X = X.to(device)\n",
    "        y = y.float().to(device)\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        mae_loss = mae(out, y)\n",
    "        \n",
    "        # statistics\n",
    "        mse += loss.item() * X.size(0)\n",
    "        mae_losses += mae_loss.item() * X.size(0)\n",
    "        \n",
    "    test_loss = mse / dataset_sizes['test']\n",
    "    test_mae_loss = mae_losses / dataset_sizes['test']\n",
    "    \n",
    "    if test_loss < baseline:\n",
    "        evaluation = 'ManGanda is performing better than the set baseline!'\n",
    "    else:\n",
    "        evaluation = 'ManGanda needs more fine-tuning'\n",
    "        \n",
    "    display(HTML(\n",
    "        '<b>'\n",
    "        f'Test MSE Loss - {test_loss:.2f}<br>'\n",
    "        f' Baseline - {baseline:.2f}<br><br>'\n",
    "        'Other Metrics:<br>'\n",
    "        f'Test MAE Loss - {test_mae_loss:.2f}<br>'\n",
    "        '----------------------------------------------------------------<br>'\n",
    "        f'{evaluation}'\n",
    "        '</b>'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a77ae3f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:21:19.837978Z",
     "start_time": "2023-06-12T15:21:19.821015Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_samples(model, dataset, n=3):\n",
    "    \"\"\"Plot sample images and print prediction\"\"\"\n",
    "    df = dataset.metadata\n",
    "    mangas = np.random.choice(df.title.unique(), n, replace=False)\n",
    "    \n",
    "    for i, manga in enumerate(mangas):\n",
    "        panels = np.random.choice(df[df['title'] == manga].index,\n",
    "                                  3,\n",
    "                                  replace=False)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        sample_data = []\n",
    "        for j, idx in enumerate(panels):\n",
    "            data = dataset[idx]\n",
    "            sample_data.append(data)\n",
    "            ax[j].imshow(transforms.ToPILImage()(data[0]))\n",
    "            ax[j].axis('off')\n",
    "\n",
    "        x, y = collate_fn(sample_data)\n",
    "        \n",
    "        if y.shape[0] < 1:\n",
    "            print('All sampled images are outliers')\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "\n",
    "        toc.add_fig(f'Sample Prediction # {i+1} - {manga}', width=100)\n",
    "        display(HTML(\n",
    "            '<center><b>'\n",
    "            f'Average Model Prediction - {out.mean().item():.2f}<br>'\n",
    "            f'   Actual Rating - {y.mean().item():.2f}'\n",
    "            '</b><center><br><br><br>'\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c45f9",
   "metadata": {},
   "source": [
    "#### Code Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c80b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:23:31.147790Z",
     "start_time": "2023-06-12T15:21:19.847559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e41975727a4a6cbbec20b3fe462a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Test MSE Loss - 0.16<br> Baseline - 0.39<br><br>Other Metrics:<br>Test MAE Loss - 0.31<br>----------------------------------------------------------------<br>ManGanda is performing better than the set baseline!</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_model(MangaModel, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0af57b79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T15:23:34.888258Z",
     "start_time": "2023-06-12T15:23:31.152205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure2.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 2.</b> Sample Prediction # 1 - Cutie Boy.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><b>Average Model Prediction - 7.72<br>   Actual Rating - 7.37</b><center><br><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure3.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 3.</b> Sample Prediction # 2 - Umi no Cradle.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><b>Average Model Prediction - 7.73<br>   Actual Rating - 7.35</b><center><br><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure4.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 4.</b> Sample Prediction # 3 - Mind Game.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><b>Average Model Prediction - 7.69<br>   Actual Rating - 7.46</b><center><br><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_samples(MangaModel, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8daf74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        Conclusion\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "Using different techniques for handling images, ManGanda was born. As evaluated using a test set, our model was able to achieve Test MSE of $0.16$ and Test MAE of $0.31$. With this, ManGanda is able to perform well enough to predict manga ratings, off only by $\\pm0.31$ on average.\n",
    "\n",
    "The performance of this model implies that manga ratings, however multidimensional, are dominantly influenced by the level of artistry. Such thought-provoking findings!\n",
    "\n",
    "Over-all, ManGanda has more room to improve and can be further leverage for XAI in cracking down the key visual elements and guide artists of what works or don't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed22099b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T01:47:26.422870Z",
     "start_time": "2023-05-29T01:47:25.591605Z"
    }
   },
   "source": [
    "***\n",
    "<div class=\"header\" style=\"\n",
    "  padding: 20px;\n",
    "  background: black;\">\n",
    "    <h2 style=\"font-family:Copperplate, Papyrus, fantasy;\n",
    "               font-size:30px;\n",
    "               font-style:bold;\n",
    "               color:white;\">\n",
    "        References\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "[1] Matthew Baas. (2019). Danbooru2018 pretrained resnet models for PyTorch. GitHub. https://github.com/RF5/danbooru-pretrained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
